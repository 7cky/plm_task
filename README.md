# plm_task
### Plm_task1 文本匹配任务

#### 一、实验目的
根据给定数据集完成文本匹配任务

#### 二、实验过程
1. **文本匹配**  
文本匹配是NLP中的核心任务，目标是判断两个文本（如句子、段落）之间的语义关系（如相似度、相关性、是否等价等）。通过模型计算两个文本的语义关联度，输出可以是分类结果（如“相关/不相关”）或相似度分数（如0-1之间的数值）。根据模型结构和处理方式的不同，文本匹配模型可分为单塔模型（PointWise）和双塔模型（DSSM、Sentence BERT）。

2. **PointWise（单塔）（有监督）**  
在整个过程中只进行一次模型计算，将两句文本进行拼接，把拼接好的数据输入模型，利用output中的CLS token做一个二分类任务，判断输入的两个文本是否匹配，可看作是一个分类问题。  
   1) **特点**  
   每判断一个样本都需要对拼接后的文本进行一次模型计算。准确率较高，计算速度慢，当类别数目较多时，效率较低。  
   2) **适用场景**  
   小规模、高精度匹配任务

3. **DSSM（双塔）（有监督）**  
将文本A和文本B分别输入两个结构相同的编码器（“塔”），得到各自的语义向量，最后通过余弦相似度计算相似度，作为匹配结果。  
   1) **特点**  
   高效性，当需要匹配新文本时，只需编码查询向量，再与库中向量快速比对。  
   无法捕捉文本A和B之间的细粒度交互（如A中的“苹果”（水果）与B中的“苹果”（公司）的区别），可能导致匹配精度低。  
   无法理解上下文语义，如一词多义等，对复杂文本匹配效果差。  
   2) **适用场景**  
   大规模文本召回任务

4. **Sentence BERT（双塔）（有监督）**  
训练时不直接对两个句子的embedding算余弦相似度，将这两个embedding和embedding之间的差向量进行拼接，拼好后喂给判别层做二分类任务。  
   1) **特点**  
   能理解上下文语义，生成的句子向量更精准，匹配精度超DSSM。  
   计算成本高  
   2) **适用场景**  
   中大规模、高精度匹配任务

5. **SimCSE（无监督）**  
通过对比学习让模型学到更精准的句子语义表征，生成更鲁棒的句子嵌入（向量），使语义相似的句子嵌入距离更近，语义不同的句子嵌入距离更远。主要用于解决传统文本匹配方法如双塔Sentence BERT在语义相似度任务上的局限性。传统方法依赖人工构造的训练数据，泛化能力有限；生成的句子嵌入在“语义相似但字面不同”的句子上区分度不足。

#### 三、实验结果
1. **实验配置**  
镜像Miniconda  conda3 Python  3.10(ubuntu22.04) CUDA  11.8  
GPU RTX 3090(24GB) * 1  
CPU14 vCPU Intel(R) Xeon(R) Gold 6330 CPU @ 2.00GHz  

2. **有监督**  
   a) **单塔pointwise**
   <img width="678" height="509" alt="9c478ace99231d59efe67e408dd2f0c3" src="https://github.com/user-attachments/assets/78ac4869-8875-40d1-a6b1-67a905ef53ef" />

   训练集损失快速下降，后稳定在0.1以下，模型学习速度快，拟合效果好。  
   验证集的准确率、精准率、召回率、F1在前500轮波动较大，模型学习不稳定，后逐渐收敛，泛化能力提升。
   <img width="606" height="191" alt="92c7871751c4f5cf2096afb096eb3a8b" src="https://github.com/user-attachments/assets/2a5c7ac1-1a47-4aee-b11d-433974ef0f3a" />

   ```
   tensor([[-1.4084,  1.1081]], device='cuda:0')
   ```  
   张量第一个值对应标签0，即两句话不相关的分数，第二个值对应标签1，即两句话相关的分数，第二个值大于第一个值，模型预测这对文本相关。  

   b) **双塔Dssm**
   <img width="694" height="520" alt="3df64c7015df4f40199db8f9b6dfbca5" src="https://github.com/user-attachments/assets/7beaaeef-ecf7-4f7b-bffe-e74681a1e89a" />

   与单塔类似，训练集快速下降并趋于稳定，模型拟合效果好。验证集准确率、精确率、召回率、F1前500轮波动剧烈，DSSM 双塔结构需分别编码句子对，初期参数更新不同步，导致验证集预测不稳定。
   <img width="656" height="124" alt="cfa361abb691f218a078bfe0b6df5a51" src="https://github.com/user-attachments/assets/4f098fb4-4f02-4994-9867-a0a6d4ea8e8e" />

   ```
   Used 0.3162384033203125s.
   [
       ('酒店', 0.9899553060531616),
       ('洗浴', 0.09616850316524506),
       ('平板', 0.01873832382261753),
       ('水果', 0.018310056999325752),
       ('蒙牛', 0.004187959246337414),
       ('电脑', -0.040313877165317535),
       ('书籍', -0.049668945372104645),
       ('衣服', -0.07240143418312073),
       ('手机', -0.08893401175737381),
       ('电器', -0.09245346486568451)
   ]
   ```  
   推理过程耗时短，模型推理效率高。能识别到“宾馆”和“酒店”的类似语义，但是果盘和“水果”的匹配效果不佳。  

   c) **双塔Sentence Bert**
   <img width="599" height="449" alt="24049f117be383d86c41287f084f8bc8" src="https://github.com/user-attachments/assets/4b930f5c-2b9d-4d4c-8e95-8bebc8b242e7" />

   ```
   Used 0.281937837600708s.
   [('酒店', 1.07696780562400818) , ('水果', 0.3312939703464508)]
   ```  
   推理耗时更短  

4. **无监督SimCSE**
   <img width="720" height="540" alt="feb8470637d69f948f17a9b630d26c40" src="https://github.com/user-attachments/assets/51bb53e6-0522-4295-94d1-e5236c8022b1" />
   <img width="865" height="162" alt="50e082f35b9639a38ea94bf44737617b" src="https://github.com/user-attachments/assets/bd92b74a-e5a8-431b-9aba-ac64e7af18f2" />


```
[0.11391016095876694, 0.5728716850280762]
```


### Plm_task2 信息抽取

#### 一、实验目的
基于通用信息抽取模型UIE完成信息抽取任务

#### 二、实验过程
1. **信息抽取**  
信息抽取旨在从非结构化文本中提取结构化信息（如实体、关系、属性等），广泛应用于命名实体识别（NER）、实体关系抽取（RE）等场景。

#### 三、实验结果
<img width="714" height="357" alt="b404ea8e5fdf9693bd45934f99cbac84" src="https://github.com/user-attachments/assets/f6ee91cc-1a91-48fc-8247-a7fb7feb71d3" />

```
[+] NER Results: 
{'人物': ['谭孝曾', '谭元寿']}
[+] Information-Extraction Results: 
{'谭孝曾': {'父亲': ['谭元寿']}, '谭元寿': {'父亲': []}}
```
<img width="865" height="541" alt="953b1268d0c7ba9a7e95e254c58ee91d" src="https://github.com/user-attachments/assets/1a5f2c37-ea21-452a-9db4-c2a4c2f94bb0" />



### Plm_task5 Prompt

#### 一、实验目的
学习两种主流的Prompt学习方法——PET（Pattern-Exploiting Training，基于人工定义模板）和P-tuning（基于机器自动学习模板）在文本分类任务中的表现。

#### 二、实验过程
1. **Prompt**  
传统微调方法需大量标注数据，而低资源场景下的性能往往不佳。Prompt学习通过构造提示模板将任务转化为掩码预测问题，充分利用预训练模型的语义理解能力，在少样本场景中表现突出。

2. **Pet**  
通过人工定义固定模板（如“这是一条{MASK}评论：{textA}”），将任务目标映射到掩码位置的预测，适用于模板易设计的场景。

3. **P-tuning**  
通过可学习的连续提示嵌入（Prompt Embedding）自动生成模板，减少人工干预，适用于模板复杂或难以定义的任务。

#### 三、实验结果
1. **PET**
   <img width="865" height="649" alt="30338b4f2090029089eaa434cc0a9187" src="https://github.com/user-attachments/assets/0380838f-154d-4ed7-b287-3867636b7155" />

```
Prompt is -> 这是一条{MASK}评论：{textA}。
Used 0.30443572998046875s.
inference label(s):
['酒店', '洗浴']
```

2. **P-tuning**
   <img width="865" height="649" alt="63ae9308e612975d7461fe3e1ab3efe4" src="https://github.com/user-attachments/assets/5155d8ab-4fe1-4a9e-a4be-9be865867015" />

   
   
```
inference label(s): ['水果', '电脑']
```


### Plm_task4 文本分类

#### 一、实验目的
使用传统微调（BERT-CLS）进行文本分类任务

#### 二、实验过程
1. **文本分类**  
将给定文本划分到预定义的类别中。其典型应用包括：情感识别（如评论的“正面”/“负面”分类）、内容类型划分（如文本属于“人物”“书籍”“城市”等类别）、主题识别（如新闻属于“政治”“体育”“娱乐”等领域）。任务本质是建立文本特征到类别标签的映射关系，传统方法依赖人工特征工程实现

#### 三、实验结果
<img width="865" height="1082" alt="6d8ff343cf2e52539186f8de40ddff77" src="https://github.com/user-attachments/assets/fe7eb371-eb65-4e95-bc81-dd9d54cbf753" />


```
global step 520, epoch: 20, loss: 0.16652, speed: 16.00 step/s
```


### Plm_task5 RLHF

#### 一、实验目的
实现基于情感识别模型的正向评论生成（无人工反馈）、基于人工打分的评论生成（有人工反馈）、奖励模型（Reward Model）训练及人工排序标注平台使用。

#### 二、实验过程
1. **RLHF**  
通过人类反馈指导语言模型优化，分为奖励模型训练和强化学习更新两个核心阶段，可显著提升模型生成效果的可控性（如情感倾向、内容质量）。

2. **基于情感识别模型的正向评论生成（无人工反馈）**  
利用预训练情感识别模型为GPT-2生成的文本打分（0~1.0），以该分数作为奖励，通过PPO算法优化GPT-2，使其生成更正向的评论。

3. **基于人工打分的评论生成（有人工反馈）**  
替换自动打分模型为人工打分，通过终端交互平台收集人工对生成文本的奖励，指导GPT-2优化。

4. **奖励模型（Reward Model）训练**  
基于排序序列数据集训练一个情感打分模型，输出文本的正向情绪分数。通过排序损失（`compute_rank_list_loss`）优化，使模型对排序序列中靠前的文本打高分，靠后的打低分。

5. **人工排序标注平台**  
基于Streamlit搭建，支持人工对模型生成的4条文本按正向情绪排序，生成奖励模型训练所需的排序序列数据。

#### 三、实验结果
1. **基于中文情感识别模型的正向评论生成机器人（No Human Reward）**  
Random Sample 5 text(s) of model output:  
1. 这次购物总的来说体验很[SEP] 声 音 小 音 质 一 般 毕 竟 不 是 巴 掌 大 的  
2. 说实话，真的很啊 。 老 妈 家 附 近 开 了 很 有 名 的 饺 子 馆  
3. 刚收到货，感觉量 很 大 就 已 经 锅 底 上 胡 子 了 ， 服 务 员  
4. 说实话，真的很般 的 一 家 店 。 12 点 半 之 前 去 的 耶 。 点  
5. 这次购物总的来说体验很. [SEP] 机 器 折 腾 的 吃 力 。 风 扇 声 很 大 其  

epoch 22 mean-reward: 0.6765008568763733  
Random Sample 5 text(s) of model output:  
1. 说实话，真的很般 般 ， 觉 得 味 还 没 有 吃 出 什 么 好 吃 的  
2. 这部电影很般 般 ， 环 境 空 气 不 好 ， 字 幕 不 清 晰 ，  
3. 说实话，真的很只 能 一 般 般 【 实 在 】 有 机 会 去 的 话 偶  
4. 刚收到货，感觉包 装 也 挺 好 的 ， 就 是 没 有 卷 ， 感 觉 有  
5. 这次购物总的来说体验很消 费 这 个 价 相 机 是 38 块 钱 。 我 想 想 您  



2. **基于人工打分的正向评论生成机器人（With Human Reward）**
   

<img width="865" height="449" alt="82ef98c379312311181590806adeb315" src="https://github.com/user-attachments/assets/c9e1cb36-6a85-4812-ac26-4aa015007d2f" />

4. **基于排序序列（Rank List）训练一个奖励模型（Reward Model）**

   <img width="865" height="216" alt="1a495ab5b3d10e650975040e161948a8" src="https://github.com/user-attachments/assets/28973ee1-1040-4da4-9197-b1846dc7e8df" />

```
tensor([[ 5.3160],
        [-4.8903]], grad_fn=<AddmmBackward0>)
```

4. **排序序列（Rank List）标注平台**
   <img width="865" height="424" alt="a7e250aad41878ee1291665c3e1a73cc" src="https://github.com/user-attachments/assets/86851051-bd96-4a6f-89fd-4f3936595b7f" />



### Plm_task6 文本生成

#### 一、实验目的

#### 二、实验过程
1. **文本生成**  
让计算机自动生成符合语法规则、语义通顺且满足特定场景需求的自然语言文本。

2. **中文问答模型**  
通过输入一个“问题”和一段“文章”，模型输出“问题的答案”。  
问答模型主要分为“抽取式”和“生成式”两类：  
抽取式问答可使用UIE模型训练，答案是从输入文章中直接抽取的片段；  
生成式问答则是由模型自主生成答案，不局限于原文内容，更具灵活性。

3. **Filling 模型（T5-Based）**  
将句子中[MASK]位置通过生成模型还原，是实现UIE信息抽取中“Mask Then Filling”数据增强策略的关键组件。对于一段文本，将其分为“关键信息段”（包含关键词的片段）和“非关键信息段”，随机mask部分“非关键信息段”后，由Filling模型还原句子，从而生成新的训练数据，增强数据集的丰富性。


### Plm_task7 大模型应用


### Plm_task8 大模型训练

#### 一、实验目的
大模型训练旨在通过优化模型参数、设计训练策略，使模型具备更强的通用能力或特定任务适配性。包括基于现有预训练模型的微调（Finetune）和从零开始的全流程训练。

#### 二、实验过程
1. **ChatGLM-6B Finetune**  
轻量级大模型，具备较强的中文理解与生成能力。尽管其在零样本场景下可处理多种任务，但存在输出格式不规范、对特定任务适配性不足等问题。可通过微调（Finetune）进一步优化模型，使其更好地对齐任务需求。  
   a) **微调方法**  
   LoRA（Low-Rank Adaptation）：通过冻结预训练模型主体参数，仅训练低秩矩阵适配参数，大幅减少训练参数规模，适用于资源有限场景。  
   P-Tuning：通过在输入序列前添加可训练的前缀（Prefix）tokens，引导模型关注任务相关信息，冻结主体模型参数，仅训练前缀编码器，能平衡性能与计算成本。

2. **从零开始训练大模型**  
在已有预训练模型基础上，使用领域内数据（如新闻、问答、百科）进一步训练，增强模型对特定领域知识的掌握。

3. **指令微调（Instruction Tuning）**  
通过人工标注的指令-响应数据（如ShareGPT）微调模型，提升其遵循自然语言指令的能力。

4. **奖励模型训练（Reward Model）**  
训练奖励模型对生成内容的质量（如相关性、安全性）打分，为后续强化学习（RL）提供反馈信号。


### Plm_task9 tool
Tokenizer Viwer 是一款方便快速预览 tokenizer 的工具

<img width="865" height="446" alt="27ed2abf3d5fd051cb447c3d5956a23c" src="https://github.com/user-attachments/assets/e8cbba51-53b9-4668-a0aa-3120824e3dc7" />

